{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40febf2-efaf-4a9b-8aaa-39b29a268c0b",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01cf10fb-6392-4c6c-9802-de3fedafc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.io as scio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.cgan import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ed3bb-63b9-47cf-b9de-f6eda2d625a0",
   "metadata": {},
   "source": [
    "# CGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae0f84-25fa-4839-af42-cda30fa6404b",
   "metadata": {},
   "source": [
    "A conditional generative adversarial network (CGAN) is a type of GAN that also takes advantage of labels during the training process.  \n",
    "\n",
    "Generator — Given a label and random array as input, this network generates data with the same structure as the training data observations corresponding to the same label.  \n",
    "\n",
    "Discriminator — Given batches of labeled data containing observations from both the training data and generated data from the generator, this network attempts to classify the observations as \"real\" or \"generated\".  \n",
    "\n",
    "![Gan](https://www.mathworks.com/help/examples/nnet/win64/TrainConditionalGenerativeAdversarialNetworkCGANExample_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264ae39-a608-4d8a-959a-e9f79fe4bc65",
   "metadata": {},
   "source": [
    "## GAN Loss\n",
    "\n",
    "- Loss_D - discriminator loss calculated as the sum of losses for the all real and all fake batches (log(D(x)) + log(1 - D(G(z)))  : WANT\n",
    "- Loss_G - generator loss calculated as log(D(G(z)))  : WANT maximize\n",
    "- D(x) - the average output (across the batch) of the discriminator for the all real batch. This should start close to 1 then theoretically converge to 0.5 when G gets better. Think about why this is.  \n",
    "- D(G(z)) - average discriminator outputs for the all fake batch. The first number is before D is updated and the second number is after D is updated. These numbers should start near 0 and converge to 0.5 as G gets better.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772bd893-106a-42c4-8a0e-aa6b2e9851a2",
   "metadata": {},
   "source": [
    "# Define Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd637c9-1c10-4b57-ab0d-5aa9d4304af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# Loss of original GAN paper.\n",
    "def train(data, num_epochs=10, batch_size=32, noise_size = 64, lr=0.0002, device='cpu', class_num=10, tag=\"\"):\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # original was MSE\n",
    "    adversarial_criterion = nn.BCELoss()\n",
    "    discriminator = Discriminator(num_classes=class_num).to(device)\n",
    "    generator = Generator(num_classes=class_num).to(device)\n",
    "    \n",
    "    fixed_noise = torch.randn([batch_size, noise_size])\n",
    "    fixed_conditional = torch.randint(0, class_num, (batch_size,))\n",
    "    \n",
    "    discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    x = data[0]\n",
    "    y = data[1]\n",
    "    global G_Loss, D_Loss, D_real, D_fake, sr_list\n",
    "    G_Loss = []\n",
    "    D_Loss = []\n",
    "    sr_list = []\n",
    "    D_real = []\n",
    "    D_fake = []\n",
    "    \n",
    "    index = 0\n",
    "    for epoch in np.arange(num_epochs):\n",
    "        discriminator.train()\n",
    "        generator.train()\n",
    "        \n",
    "        \n",
    "        for i, (inputs, target) in enumerate(zip(x,y)):\n",
    "            inputs = torch.Tensor(inputs).to(device)\n",
    "            target = torch.IntTensor(target).to(device)\n",
    "            \n",
    "            real_label = torch.ones(batch_size, 1).to(device)\n",
    "            fake_label = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            noise = torch.randn([batch_size, noise_size]).to(device)\n",
    "            conditional = torch.randint(0, class_num, (batch_size,)).to(device)\n",
    "            \n",
    "            # d_loss true\n",
    "            real_output = discriminator(inputs, target)\n",
    "            d_loss_real = adversarial_criterion(real_output, real_label)\n",
    "            D_x = real_output.detach().cpu().mean().item()\n",
    "            \n",
    "            # d_loss fake\n",
    "            fake = generator(noise, conditional)\n",
    "            fake_output = discriminator(fake.detach(), conditional)\n",
    "            d_loss_fake = adversarial_criterion(fake_output, fake_label)\n",
    "            D_G_z = fake_output.detach().cpu().mean().item()\n",
    "            \n",
    "            # d_loss total\n",
    "            d_loss = d_loss_fake + d_loss_real\n",
    "            \n",
    "            # d train\n",
    "            discriminator.zero_grad()\n",
    "            generator.zero_grad()\n",
    "            d_loss.backward()\n",
    "            discriminator_optimizer.step()\n",
    "            \n",
    "            # g loss\n",
    "            fake = generator(noise, conditional)\n",
    "            fake_output = discriminator(fake.detach(), conditional)\n",
    "            g_loss = adversarial_criterion(fake_output, real_label)\n",
    "            \n",
    "            # g train\n",
    "            discriminator.zero_grad()\n",
    "            generator.zero_grad()\n",
    "            g_loss.backward()\n",
    "            discriminator_optimizer.step()\n",
    "            \n",
    "            errG = g_loss.detach().cpu().mean().item()\n",
    "            errD = d_loss.detach().cpu().mean().item()\n",
    "            \n",
    "            G_Loss.append(errG)\n",
    "            D_Loss.append(errD)\n",
    "            \n",
    "            if(index%100 == 0):\n",
    "                print(\"Epoch:\", epoch, \"Global Iter: \",index,\"Current G Loss : %.2f\" % errG,\"Current D Loss : %.2f\" % errD, end=\" \")\n",
    "                print(\"D(x): %.2f\" %  D_x, \"D(G(z)): %.2f\" % D_G_z)\n",
    "            index+=1\n",
    "\n",
    "        # Evaluation\n",
    "        with torch.no_grad():\n",
    "            generator.eval()\n",
    "            sr = generator(fixed_noise.to(device), fixed_conditional.to(device))\n",
    "            ## make some visualization or saving file func\n",
    "            # Func(sr, path)\n",
    "            sr_list.append(sr.detach().cpu())\n",
    "            \n",
    "            torch.save(generator.state_dict(), f\"./model_ckpt/ckpt{epoch}_generator_{tag}.pt\")\n",
    "            torch.save(discriminator.state_dict(), f\"./model_ckpt/ckpt{epoch}_discriminator_{tag}.pt\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c366f-e8f0-4c98-8e84-f180363bddc4",
   "metadata": {},
   "source": [
    "# Load Dataset & Data Batch Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e82ad9-395a-4024-8710-99d05256c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan_dataset = scio.loadmat(\"./cgan_dataset.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbf024a-23c1-47b4-894c-c8020b0f5ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((695, 32, 1, 200), (695, 32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "x = []\n",
    "y = []\n",
    "iteration = cgan_dataset[\"X\"].shape[0] // batch_size\n",
    "for i in range((iteration-1)):\n",
    "    x.append(cgan_dataset['X'][batch_size*i: batch_size*(i+1)])\n",
    "    y.append(cgan_dataset['Y'][0][batch_size*i: batch_size*(i+1)])\n",
    "    \n",
    "x = np.array(x, dtype=float)\n",
    "x = np.expand_dims(x, 2)\n",
    "y = np.array(y, dtype=int)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcdf810-352b-43be-9cb4-b3c72f2f3c0f",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ba2907-8f40-455c-bb98-c0d0af70a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Global Iter:  0 Current G Loss : 0.69 Current D Loss : 1.39 D(x): 0.50 D(G(z)): 0.50\n",
      "Epoch: 0 Global Iter:  100 Current G Loss : 0.68 Current D Loss : 1.33 D(x): 0.54 D(G(z)): 0.51\n",
      "Epoch: 0 Global Iter:  200 Current G Loss : 0.54 Current D Loss : 1.15 D(x): 0.77 D(G(z)): 0.58\n",
      "Epoch: 0 Global Iter:  300 Current G Loss : 0.48 Current D Loss : 1.17 D(x): 0.83 D(G(z)): 0.62\n",
      "Epoch: 0 Global Iter:  400 Current G Loss : 0.51 Current D Loss : 1.02 D(x): 0.93 D(G(z)): 0.61\n",
      "Epoch: 0 Global Iter:  500 Current G Loss : 0.52 Current D Loss : 1.19 D(x): 0.77 D(G(z)): 0.60\n",
      "Epoch: 0 Global Iter:  600 Current G Loss : 0.55 Current D Loss : 0.97 D(x): 0.93 D(G(z)): 0.58\n",
      "Epoch: 1 Global Iter:  700 Current G Loss : 0.59 Current D Loss : 0.88 D(x): 0.95 D(G(z)): 0.56\n",
      "Epoch: 1 Global Iter:  800 Current G Loss : 0.63 Current D Loss : 0.92 D(x): 0.88 D(G(z)): 0.54\n",
      "Epoch: 1 Global Iter:  900 Current G Loss : 0.61 Current D Loss : 0.88 D(x): 0.95 D(G(z)): 0.55\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35404/3079592274.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00002\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_35404/1702258691.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data, num_epochs, batch_size, noise_size, lr, device, class_num, tag)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mreal_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mfake_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(data=[x,y], num_epochs=1000, batch_size=32, lr=0.00002, device='cuda', class_num=18, tag=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18736ba-2aeb-4f46-951b-f6f77ad9b9e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d347d-4ae8-4202-ada3-fc9818b4ac7b",
   "metadata": {},
   "source": [
    "# Load Model and Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d786da7-48b5-4fd1-9480-3a3583c06ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 18\n",
    "batch_size = 100\n",
    "noise_size = 64\n",
    "\n",
    "model = Generator(num_classes=class_num)\n",
    "_input = torch.randn([batch_size, noise_size])\n",
    "_class =  torch.randint(0, class_num, (batch_size,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e818e-2427-4a05-b22e-c9e0583845b2",
   "metadata": {},
   "source": [
    "### Load from state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786c0143-3320-4b86-9074-1c950fdf99e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "i = 694\n",
    "tag = \"\"\n",
    "########################################\n",
    "\n",
    "model.load_state_dict(torch.load(f\"./model_ckpt/ckpt{i}_generator_{tag}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d035305-ac9f-4180-8034-0a1c345c8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(_input, _class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc543a-1aee-497f-8a27-b52153a5f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./gan_results/gan_output.npy\", results.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda37",
   "language": "python",
   "name": "cuda37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
