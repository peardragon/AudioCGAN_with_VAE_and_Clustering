{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0679778-116e-406e-a013-410aa85bcd5c",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03df4a5d-03e6-4309-ade4-787508d2d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import scipy.io as scio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.unrolled_cgan import Generator, Discriminator, GANLoops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a957a-38be-4abf-9fa7-671493d3debf",
   "metadata": {},
   "source": [
    "# Define Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1d91d3b-f3ad-4081-8d24-df11fda61095",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### HYPERPARAMS ####################\n",
    "unrolled_steps = 10\n",
    "num_updates_per_epoch = 500\n",
    "d_steps = 1\n",
    "g_steps = 1\n",
    "####################################################\n",
    "\n",
    "def train(dataset, num_epochs=1000, batch_size=32, noise_size = 64, lr=0.0002, device='cpu', class_num=10, tag=\"\"):\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    D = Discriminator(num_classes=class_num).to(device)\n",
    "    G = Generator(num_classes=class_num).to(device)\n",
    "    \n",
    "    fixed_noise = torch.randn([batch_size, noise_size])\n",
    "    fixed_conditional = torch.randint(0, class_num, (batch_size,))\n",
    "    \n",
    "    discriminator_optimizer = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    generator_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    global G_Loss, D_Loss, D_real, D_fake, samples\n",
    "    G_Loss = []\n",
    "    D_Loss = []\n",
    "    D_real = []\n",
    "    D_fake = []\n",
    "    samples = []\n",
    "    index = 0\n",
    "    \n",
    "    gan_loops = GANLoops(dataset, class_num, device = device)\n",
    "    \n",
    "    for epoch in np.arange(num_epochs):\n",
    "        D.train()\n",
    "        G.train()\n",
    "        \n",
    "        for t in np.arange(num_updates_per_epoch):\n",
    "            d_infos = []\n",
    "            for d_index in range(d_steps):\n",
    "                d_info = gan_loops.d_loop(G, D, discriminator_optimizer, criterion)\n",
    "                d_infos.append(d_info)\n",
    "            d_infos = np.mean(d_infos, 0)\n",
    "            d_real_loss, d_fake_loss, D_G_z, D_x = d_infos\n",
    "\n",
    "            g_infos = []\n",
    "            for g_index in range(g_steps):\n",
    "                g_info = gan_loops.g_loop(G, D, generator_optimizer, discriminator_optimizer, \n",
    "                                          criterion, unrolled_steps=unrolled_steps)\n",
    "                g_infos.append(g_info)\n",
    "            g_infos = np.mean(g_infos)\n",
    "            g_loss = g_infos\n",
    "\n",
    "\n",
    "            errG = g_loss\n",
    "            errD = d_real_loss + d_fake_loss\n",
    "            G_Loss.append(errG)\n",
    "            D_Loss.append(errD)\n",
    "            D_real.append(D_x)\n",
    "            D_fake.append(D_G_z)\n",
    "            \n",
    "            if(index%100 == 0):\n",
    "                print(\"Epoch:\", epoch, \"Global Iter: \",index,\"Current G Loss : %.2f\" % errG,\"Current D Loss : %.2f\" % errD, end=\" \")\n",
    "                print(\"D(x): %.2f\" %  D_x, \"D(G(z)): %.2f\" % D_G_z)\n",
    "            index+=1\n",
    "        \n",
    "        # Evaluation\n",
    "        with torch.no_grad():\n",
    "            G.eval()\n",
    "            sr = G(fixed_noise.to(device), fixed_conditional.to(device))\n",
    "            ## make some visualization or saving file func\n",
    "            samples.append(sr.detach().cpu())\n",
    "            \n",
    "            torch.save(G.state_dict(), f\"./model_ckpt/ckpt{epoch}_generator_{tag}.pt\")\n",
    "            torch.save(D.state_dict(), f\"./model_ckpt/ckpt{epoch}_discriminator_{tag}.pt\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b73cb6-94b9-45e6-9329-963a83d3e642",
   "metadata": {},
   "source": [
    "# Load Dataset & Data Batch Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c62b6b95-9d79-42cd-a652-225dcbc2c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan_dataset = scio.loadmat(\"./cgan_dataset.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d17925a1-dc6a-4c42-b9d7-2521dafe7ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((695, 32, 1, 200), (695, 32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "x = []\n",
    "y = []\n",
    "iteration = cgan_dataset[\"X\"].shape[0] // batch_size\n",
    "for i in range((iteration-1)):\n",
    "    x.append(cgan_dataset['X'][batch_size*i: batch_size*(i+1)])\n",
    "    y.append(cgan_dataset['Y'][0][batch_size*i: batch_size*(i+1)])\n",
    "    \n",
    "x = np.array(x, dtype=float)\n",
    "x = np.expand_dims(x, 2)\n",
    "y = np.array(y, dtype=int)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d89fe-62f7-46b4-bc39-6289a7cfebe7",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878c2ab-6a23-4683-a41f-53f80ab63dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train((x,y), num_epochs=3000, class_num=18, device=\"cuda\", tag=\"unrolled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826158e5-984e-4f43-99f6-927578e819ff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4000b92-4fea-48e2-b775-1d4d35173d14",
   "metadata": {},
   "source": [
    "# Load Model and Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19b1d05e-27f4-4940-b407-3b93c698e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 18\n",
    "batch_size = 100\n",
    "noise_size = 64\n",
    "\n",
    "model = Generator(num_classes=class_num)\n",
    "_input = torch.randn([batch_size, noise_size])\n",
    "_class =  torch.randint(0, class_num, (batch_size,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb8476-7898-4af5-8c83-b07d944d36a1",
   "metadata": {},
   "source": [
    "### Load from state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2dc171d-aceb-4f3f-a0bd-3ae0d1b90cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################\n",
    "i = 0\n",
    "tag = \"unrolled\"\n",
    "########################################\n",
    "\n",
    "model.load_state_dict(torch.load(f\"./model_ckpt/ckpt{i}_generator_{tag}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b54a3852-2aa7-4efc-b0af-86a498e6bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(_input, _class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eed2c6fd-e7cf-4bdf-a6ce-58d68b581433",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./gan_results/gan_output.npy\", results.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda37",
   "language": "python",
   "name": "cuda37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
